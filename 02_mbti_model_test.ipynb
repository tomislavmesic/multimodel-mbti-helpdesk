{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=r'.*Use subset.*of np.ndarray is not recommended')\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/mbti_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary from 1500 words that are not common words or MBTI personalities\n",
    "vectorizer = CountVectorizer(stop_words = ['and','the','to','of','infj','entp','intp','intj','entj','enfj','infp','enfp','isfp','istp','isfj','istj','estp','esfp','estj','esfj','infjs','entps','intps','intjs','entjs','enfjs','infps','enfps','isfps','istps','isfjs','istjs','estps','esfps','estjs','esfjs'], max_features=1500, analyzer='word', max_df=0.8, min_df=0.1)\n",
    "\n",
    "corpus = df['clean_posts'].values.reshape(1,-1).tolist()[0]\n",
    "\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "X_cnt = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Transform the count matrix to a tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "tfizer.fit(X_cnt)\n",
    "\n",
    "X = tfizer.fit_transform(X_cnt).toarray()\n",
    "\n",
    "all_words = vectorizer.get_feature_names()\n",
    "\n",
    "n_words = len(all_words)\n",
    "\n",
    "X_df = pd.DataFrame.from_dict({w: X[:, i] for i, w in enumerate(all_words)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_random_oversample(X_train, y_train):\n",
    "    oversampler = RandomOverSampler(sampling_strategy=0.9, random_state=0)\n",
    "    \n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_smote_oversample(X_train, y_train):\n",
    "    oversampler = SMOTE(random_state=0)\n",
    "    \n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_smote_oversample_random_undersample(X_train, y_train):\n",
    "    oversampler = SMOTE(sampling_strategy=0.9, random_state=0) \n",
    "    undersampler = RandomUnderSampler(sampling_strategy=0.9, random_state=0)\n",
    "\n",
    "    # Applying oversampler to oversample the minority class\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Applying undersampler to reduce the majority class\n",
    "    X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_borderlinesmote_oversample(X_train, y_train):\n",
    "    oversampler = BorderlineSMOTE(random_state=0)\n",
    "    \n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_smoteenn_oversample_random_undersample(X_train, y_train):\n",
    "    oversampler = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "    undersampler = RandomUnderSampler(sampling_strategy=0.7, random_state=0)\n",
    "    \n",
    "    # Apply SMOTEENN (combination of SMOTE and ENN)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply random undersampling\n",
    "    X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_smoteen_adasyn_oversample_random_undersample(X_train, y_train):\n",
    "    oversampler_1 = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "    oversampler_2 = ADASYN(sampling_strategy=0.6, random_state=0, n_neighbors=5)\n",
    "    undersampler = RandomUnderSampler(sampling_strategy=0.7, random_state=0)\n",
    "\n",
    "    # Balance the dataset using a combination of SMOTE and ENN\n",
    "    X_resampled, y_resampled = oversampler_1.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply ADASYN for additional oversampling\n",
    "    X_resampled, y_resampled = oversampler_2.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "    # Apply additional undersampling to reduce the majority class size\n",
    "    X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Dummy': lambda: DummyClassifier(strategy='most_frequent', random_state=42),\n",
    "    'SVM': lambda: SVC(probability=True, random_state=42),\n",
    "    'LGBM': lambda: LGBMClassifier(random_state=42),\n",
    "    'KNeighbors': lambda: KNeighborsClassifier(),    \n",
    "    'DecisionTree': lambda: DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': lambda: RandomForestClassifier(random_state=42),\n",
    "    'AdaBoost': lambda: AdaBoostClassifier(),\n",
    "    'GradientBoosting': lambda: GradientBoostingClassifier(),\n",
    "    'GaussianNB': lambda: GaussianNB(),\n",
    "    'LogisticRegression': lambda: LogisticRegression(random_state=42),\n",
    "    'XGB': lambda: XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'VotingClassifier': lambda: VotingClassifier(estimators=[\n",
    "        ('SVM', SVC(probability=True, random_state=42)),\n",
    "        ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "        ('LogisticRegression', LogisticRegression(random_state=42)),\n",
    "        ('XGB', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "    ], voting='soft')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplers = {\n",
    "  'RandomOverSampler': 'balance_random_oversample',\n",
    "  'SMOTE': 'balance_smote_oversample',\n",
    "  'SMOTE + RandomUnderSampler': 'balance_smote_oversample_random_undersample',\n",
    "  'BorderlineSMOTE': 'balance_borderlinesmote_oversample',\n",
    "  'SMOTEENN + RandomUnderSampler': 'balance_smoteenn_oversample_random_undersample',\n",
    "  'SMOTEENN & ADASYN + RandomUnderSampler': 'balance_smoteen_adasyn_oversample_random_undersample'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(class_name, resampler=None):\n",
    "  y_df = df[class_name]\n",
    "  \n",
    "  if resampler == None:\n",
    "    X_cl = X_df\n",
    "    y_cl = y_df\n",
    "  else:\n",
    "    rs = resamplers[resampler]\n",
    "\n",
    "    X_cl, y_cl = globals()[rs](X_df, y_df)\n",
    "\n",
    "  X_cl_train, X_cl_test, y_cl_train, y_cl_test = train_test_split(X_cl, y_cl, test_size=0.2, random_state=42, stratify=y_cl)\n",
    "\n",
    "  return X_cl_train, X_cl_test, y_cl_train, y_cl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class model based on classifer and balancer\n",
    "def classifier_model(class_name, classifier, resampler=None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split_data(class_name, resampler)\n",
    "    \n",
    "    model_classifier = classifiers[classifier]()\n",
    "\n",
    "    model = model_classifier.fit(X_train, y_train)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mbti(model, text):\n",
    "    final_test = tfizer.transform(vectorizer.transform([text.lower()])).toarray()\n",
    "\n",
    "    test_point = pd.DataFrame.from_dict({w: final_test[:, i] for i, w in enumerate(all_words)})\n",
    "\n",
    "    test_result = model.predict_proba(test_point)\n",
    "\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performed models\n",
    "ei_model = classifier_model('E_I', 'RandomForest', 'RandomOverSampler')\n",
    "sn_model = classifier_model('S_N', 'RandomForest', 'RandomOverSampler')\n",
    "tf_model = classifier_model('T_F', 'SVM')\n",
    "jp_model = classifier_model('J_P', 'VotingClassifier', 'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85 0.15]]\n",
      "I\n",
      "[[0.71 0.29]]\n",
      "N\n",
      "[[0.71456327 0.28543673]]\n",
      "F\n",
      "[[0.46536414 0.53463586]]\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "# Models test\n",
    "helpdesk_topic = \"To Whom It May Concern, I am writing today to complain of the poor service I received from your company on June 12, 2023. I was visited by a representative of That Awful Company, Mr. Madman, at my home on that day. I trust this is not the way That Awful Company wishes to conduct business with valued customers—I have been with you since the company was founded and have never encountered such treatment before. I would welcome the opportunity to discuss matters further and to learn of how you propose to prevent a similar situation from recurring. I look forward to hearing from you. Yours faithfully, Customer\"\n",
    "\n",
    "# E_I model test\n",
    "ei_class_res = test_mbti(ei_model, helpdesk_topic)\n",
    "ei_class_str = 'E' if (ei_class_res[0][0] < ei_class_res[0][1]) else 'I'\n",
    "\n",
    "print(ei_class_res)\n",
    "print(ei_class_str)\n",
    "\n",
    "# S_N model test\n",
    "sn_class_res = test_mbti(sn_model, helpdesk_topic)\n",
    "sn_class_str = 'S' if (sn_class_res[0][0] < sn_class_res[0][1]) else 'N'\n",
    "\n",
    "print(sn_class_res)\n",
    "print(sn_class_str)\n",
    "\n",
    "# model test\n",
    "tf_class_res = test_mbti(tf_model, helpdesk_topic)\n",
    "tf_class_str = 'T' if (tf_class_res[0][0] < tf_class_res[0][1]) else 'F'\n",
    "\n",
    "print(tf_class_res)\n",
    "print(tf_class_str)\n",
    "\n",
    "# model test\n",
    "jp_class_res = test_mbti(jp_model, helpdesk_topic)\n",
    "jp_class_str = 'J' if (jp_class_res[0][0] < jp_class_res[0][1]) else 'P'\n",
    "\n",
    "print(jp_class_res)\n",
    "print(jp_class_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Recognized MBTI Types: 85.6% (7422/8675)\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Test class models on cleaned data #\n",
    "#####################################\n",
    "\n",
    "test_df = pd.read_csv('input/mbti_data_clean.csv')\n",
    "\n",
    "test_mbti_classifications = []\n",
    "\n",
    "correct_types = 0\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    t = test_df.iloc[i]['clean_posts']\n",
    "    type = test_df.iloc[i]['type']\n",
    "\n",
    "    ei = test_mbti(ei_model, t)\n",
    "    ei_str = 'E' if (ei[0][0] < ei[0][1]) else 'I'\n",
    "\n",
    "    sn = test_mbti(sn_model, t)\n",
    "    sn_str = 'S' if sn[0][0] < sn[0][1] else 'N'\n",
    "\n",
    "    tf = test_mbti(tf_model, t)\n",
    "    tf_str = 'T' if tf[0][0] < tf[0][1] else 'F'\n",
    "\n",
    "    jp = test_mbti(jp_model, t)\n",
    "    jp_str = 'J' if jp[0][0] < jp[0][1] else 'P'\n",
    "\n",
    "    mbti_type = ei_str + sn_str + tf_str + jp_str\n",
    "\n",
    "    test_mbti_classifications.append(mbti_type)\n",
    "\n",
    "    if mbti_type == type:\n",
    "        correct_types = correct_types + 1\n",
    "\n",
    "print('Correctly Recognized MBTI Types: {:0.1f}% ({:n}/{:n})'.format(correct_types/len(test_df)*100, correct_types, len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Recognized MBTI Types: 83.9% (7276/8675)\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Test class models on raw data #\n",
    "#################################\n",
    "\n",
    "df_orig = pd.read_csv('input/mbti_data.csv')\n",
    "\n",
    "test_df = df_orig.copy()\n",
    "\n",
    "test_mbti_classifications = []\n",
    "\n",
    "correct_types = 0\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    t = test_df.iloc[i]['posts']\n",
    "    type = test_df.iloc[i]['type']\n",
    "\n",
    "    ei = test_mbti(ei_model, t)\n",
    "    ei_str = 'E' if (ei[0][0] < ei[0][1]) else 'I'\n",
    "\n",
    "    sn = test_mbti(sn_model, t)\n",
    "    sn_str = 'S' if sn[0][0] < sn[0][1] else 'N'\n",
    "\n",
    "    tf = test_mbti(tf_model, t)\n",
    "    tf_str = 'T' if tf[0][0] < tf[0][1] else 'F'\n",
    "\n",
    "    jp = test_mbti(jp_model, t)\n",
    "    jp_str = 'J' if jp[0][0] < jp[0][1] else 'P'\n",
    "\n",
    "    mbti_type = ei_str + sn_str + tf_str + jp_str\n",
    "\n",
    "    test_mbti_classifications.append(mbti_type)\n",
    "\n",
    "    if mbti_type == type:\n",
    "        correct_types = correct_types + 1\n",
    "\n",
    "print('Correctly Recognized MBTI Types: {:0.1f}% ({:n}/{:n})'.format(correct_types/len(test_df)*100, correct_types, len(test_df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbti_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb2a74056668a37b1e70d58465c542cd41f068be1a294d62341136952e9c6170"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
